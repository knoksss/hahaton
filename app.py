from flask import Flask, request, jsonify, render_template, redirect, url_for
from flask_cors import CORS
from openai import OpenAI
import os
import json
import time
from datetime import datetime

app = Flask(__name__)
CORS(app)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
class Config:
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ SciBox
    LLM_BASE_URL = "https://llm.t1v.scibox.tech/v1"
    LLM_MODEL = "qwen3-32b-awq"
    LLM_TOKEN = "sk--hwyMZDmxjPMm50_5LXTiA"  # ‚ö†Ô∏è –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –†–ï–ê–õ–¨–ù–´–ô –¢–û–ö–ï–ù ‚ö†Ô∏è
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    TEMPERATURE = 0.7
    TOP_P = 0.9
    MAX_TOKENS = 1000
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    INTERVIEW_DURATION = 30
    MAX_QUESTIONS = 5

app.config.from_object(Config)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(
    api_key="sk--hwyMZDmxjPMm50_5LXTiA",
    base_url=Config.LLM_BASE_URL
)

# –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö
class InterviewSession:
    def __init__(self, session_id, position, level, interview_type, company_type):
        self.session_id = session_id
        self.position = position
        self.level = level
        self.interview_type = interview_type
        self.company_type = company_type
        self.questions_asked = []
        self.user_answers = []
        self.current_question = None
        self.start_time = datetime.now()
        self.is_active = True
        self.question_count = 0
        
    def to_dict(self):
        return {
            'session_id': self.session_id,
            'position': self.position,
            'level': self.level,
            'interview_type': self.interview_type,
            'company_type': self.company_type,
            'questions_asked': self.questions_asked,
            'user_answers': self.user_answers,
            'current_question': self.current_question,
            'start_time': self.start_time.isoformat(),
            'is_active': self.is_active,
            'question_count': self.question_count
        }

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π
interview_sessions = {}

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∏ —É—Ä–æ–≤–Ω–∏
AVAILABLE_POSITIONS = {
    "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["HTML/CSS", "JavaScript", "React", "Vue", "TypeScript", "Webpack"],
    "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["Python", "Java", "Node.js", "SQL", "Docker", "AWS"],
    "Data Scientist": ["Python", "Machine Learning", "SQL", "Statistics", "Deep Learning"],
    "DevOps –∏–Ω–∂–µ–Ω–µ—Ä": ["Docker", "Kubernetes", "AWS", "CI/CD", "Linux", "Networking"],
    "Mobile —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["Android", "iOS", "React Native", "Flutter", "Kotlin", "Swift"]
}

AVAILABLE_LEVELS = ["Junior", "Middle", "Senior", "Team Lead"]
AVAILABLE_INTERVIEW_TYPES = ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ", "–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–µ", "–°–∏—Å—Ç–µ–º–Ω–æ–µ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ", "–°–º–µ—à–∞–Ω–Ω–æ–µ"]
AVAILABLE_COMPANY_TYPES = ["IT –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è", "–ê—É—Ç—Å–æ—Ä—Å–∏–Ω–≥", "–°—Ç–∞—Ä—Ç–∞–ø", "–ö—Ä—É–ø–Ω–∞—è –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–ì–æ—Å—É—á—Ä–µ–∂–¥–µ–Ω–∏–µ"]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å LLM —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç
def chat_with_model(messages, model=Config.LLM_MODEL):
    try:
        print(f"üîß –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç")
        print(f"   Model: {model}")

        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=Config.TEMPERATURE,
            top_p=Config.TOP_P,
            max_tokens=Config.MAX_TOKENS
        )

        print("‚úÖ LLM –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏:
        debug_llm_response(response)

        return response

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å LLM: {e}")
        raise e

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ LLM
def generate_interview_question(session, previous_answers=None):
    try:
        # –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"""
–í–æ–ø—Ä–æ—Å—ã –∑–∞–¥–∞–≤–∞—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
ROLE: Technical interviewer for {session.position} {session.level} position
INTERVIEW TYPE: {session.interview_type}
COMPANY: {session.company_type}

PREVIOUS QUESTIONS: {session.questions_asked[-2:] if session.questions_asked else 'None'}

TASK: Generate exactly ONE technical interview question.

REQUIREMENTS:
- Must be a single question only
- Technical and relevant to {session.position}
- Appropriate for {session.level} level
- Different from previous questions
- Practical and skills-focused

FORMAT: Return ONLY the question text, nothing else.

QUESTION:
"""

        messages = [
            {
                "role": "system",
                "content": "You are a technical interviewer. Generate exactly one interview question. Return ONLY the question text without any additional text, explanations, or formatting."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        print(f"üéØ Generating question for {session.position} {session.level}")
        response = chat_with_model(messages)
        question = response.choices[0].message.content.strip()

        print(f"üì® Raw LLM response: '{question}'")

        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
        question = clean_llm_response(question)

        # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Å—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        if not question or len(question.strip()) < 15 or not any(char.isalpha() for char in question):
            print("‚ùå LLM returned empty or invalid question, using fallback")
            return get_fallback_question(session)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–æ–ø—Ä–æ—Å (—Å–æ–¥–µ—Ä–∂–∏—Ç –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–Ω–æ–µ —Å–ª–æ–≤–æ)
        question_words = ['–∫–∞–∫', '—á—Ç–æ', '–ø–æ—á–µ–º—É', '—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ', '–æ–±—ä—è—Å–Ω–∏—Ç–µ', 'how', 'what', 'why', 'explain']
        has_question_mark = '?' in question
        starts_with_question_word = any(question.lower().startswith(word) for word in question_words)

        if not (has_question_mark or starts_with_question_word):
            print("‚ö†Ô∏è LLM response doesn't look like a question, using fallback")
            return get_fallback_question(session)

        print(f"‚úÖ Generated question: {question}")
        return question

    except Exception as e:
        print(f"‚ùå Error generating question with LLM: {e}")
        return get_fallback_question(session)


def clean_llm_response(text):
    """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM –æ—Ç –ª–∏—à–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
    if not text:
        return text

    # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    text = text.strip('"\'').strip()

    # –£–¥–∞–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –∫–æ–¥–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    formatting_marks = ['```json', '```python', '```', 'QUESTION:', '–í–æ–ø—Ä–æ—Å:', 'Answer:', '–û—Ç–≤–µ—Ç:']
    for mark in formatting_marks:
        text = text.replace(mark, '').strip()

    # –£–¥–∞–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –≤ –Ω–∞—á–∞–ª–µ (1. 2. –∏ —Ç.–¥.)
    import re
    text = re.sub(r'^\d+[\.\)]\s*', '', text)

    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã)
    lines = text.split('\n')
    if len(lines) > 1:
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ–µ
        if len(lines[0].strip()) > 20:
            text = lines[0].strip()
        else:
            # –ò–Ω–∞—á–µ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏
            text = ' '.join(lines[:2]).strip()

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∑–Ω–∞–∫–æ–º –≤–æ–ø—Ä–æ—Å–∞
    if text and not text.endswith('?') and len(text) > 10:
        text = text + '?'

    return text


def debug_llm_response(response):
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ LLM"""
    if not response or not hasattr(response, 'choices'):
        print("üîç DEBUG: No response or invalid response object")
        return

    choice = response.choices[0]
    message = choice.message

    print(f"üîç DEBUG LLM RESPONSE:")
    print(f"   Finish reason: {choice.finish_reason}")
    print(f"   Content: '{message.content}'")
    print(f"   Content length: {len(message.content)}")
    print(f"   Role: {message.role}")

    # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏—è
    for attr in dir(message):
        if not attr.startswith('_'):
            value = getattr(message, attr)
            if value and attr != 'content':
                print(f"   {attr}: {value}")

def get_fallback_question(session):
    """Fallback –≤–æ–ø—Ä–æ—Å—ã –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    questions_pool = {
        "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": {
            "Junior": [
                "–û–±—ä—è—Å–Ω–∏—Ç–µ, —á—Ç–æ —Ç–∞–∫–æ–µ DOM –∏ –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç?",
                "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É let, const –∏ var?",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ event delegation –∏ –∑–∞—á–µ–º –æ–Ω–æ –Ω—É–∂–Ω–æ?",
            ],
            "Middle": [
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–≤–æ–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ JavaScript",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π?",
                "–û–±—ä—è—Å–Ω–∏—Ç–µ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É React –∏ Vue",
            ],
            "Senior": [
                "–û–ø–∏—à–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∫—Ä—É–ø–Ω–æ–≥–æ frontend –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞?",
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π",
            ]
        },
        "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": {
            "Junior": [
                "–ß—Ç–æ —Ç–∞–∫–æ–µ REST API?",
                "–û–±—ä—è—Å–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –û–û–ü",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ SQL –∏–Ω—ä–µ–∫—Ü–∏–∏ –∏ –∫–∞–∫ –∏—Ö –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å?",
            ],
            "Middle": [
                "–û–ø–∏—à–∏—Ç–µ –≤–∞—à –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å API?",
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã —Å –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏",
            ],
            "Senior": [
                "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã?",
                "–û–ø–∏—à–∏—Ç–µ –≤–∞—à –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å message brokers",
            ]
        }
    }
    
    position_questions = questions_pool.get(session.position, questions_pool["Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"])
    level_questions = position_questions.get(session.level, position_questions["Middle"])
    available_questions = [q for q in level_questions if q not in session.questions_asked]
    
    if available_questions:
        return available_questions[0]
    else:
        return f"–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–∞–º–æ–º —Å–ª–æ–∂–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {session.position}, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å?"

# –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM
def evaluate_answer(question, answer, position, level, contains_code=False, language=None):
    try:
        if contains_code:
            prompt = f"""
            –í–û–ü–†–û–°: {question}
            –ö–û–î ({language}):
            {answer}

            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
            1. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è
            2. –ö–∞—á–µ—Å—Ç–≤–æ –∏ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞
            3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞
            4. –û–±—Ä–∞–±–æ—Ç–∫–∞ edge cases
            5. –°–ª–µ–¥–æ–≤–∞–Ω–∏–µ best practices

            –û–¶–ï–ù–ö–ê: –æ—Ç 1 –¥–æ 10
            –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´: 2-3 –ø—É–Ω–∫—Ç–∞
            –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: 2-3 –ø—É–Ω–∫—Ç–∞

            –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
            –û–¶–ï–ù–ö–ê: [—á–∏—Å–ª–æ]/10
            –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]
            –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]
            """
        else:
            prompt = f"""
            –í–û–ü–†–û–°: {question}
            –û–¢–í–ï–¢: {answer}

            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
            1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≥–ª—É–±–∏–Ω–∞ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å
            2. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –∑–Ω–∞–Ω–∏–π
            3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
            4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Ä–æ–≤–Ω—é –ø–æ–∑–∏—Ü–∏–∏ {level}
            5. –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

            –û–¶–ï–ù–ö–ê: –æ—Ç 1 –¥–æ 10
            –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´: 2-3 –ø—É–Ω–∫—Ç–∞
            –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: 2-3 –ø—É–Ω–∫—Ç–∞

            –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
            –û–¶–ï–ù–ö–ê: [—á–∏—Å–ª–æ]/10
            –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]
            –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]
            """

        messages = [
            {
                "role": "system",
                "content": """–¢—ã —Å—Ç—Ä–æ–≥–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –¥–∞–≤–∞–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.

–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –≤ —Å—Ç—Ä–æ–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:
–û–¶–ï–ù–ö–ê: [—á–∏—Å–ª–æ]/10
–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]
–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: [–ø—É–Ω–∫—Ç1], [–ø—É–Ω–∫—Ç2], [–ø—É–Ω–∫—Ç3]

–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        print(f"üìä –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Ü–µ–Ω–∫—É –æ—Ç–≤–µ—Ç–∞")
        response = chat_with_model(messages)
        evaluation_text = response.choices[0].message.content.strip()

        print(f"üì® –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM: {evaluation_text}")

        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –≤–º–µ—Å—Ç–æ JSON
        evaluation = parse_text_evaluation(evaluation_text, contains_code)

        print(f"‚úÖ –û—Ü–µ–Ω–∫–∞ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞: {evaluation['score']}/10")
        return evaluation

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return get_fallback_evaluation(contains_code, 5)


def parse_text_evaluation(text, contains_code=False):
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É"""
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É
        evaluation = {
            "score": 5,
            "feedback": "–û—Ç–≤–µ—Ç —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
            "strengths": [],
            "improvements": []
        }

        if contains_code:
            evaluation["code_analysis"] = {
                "correctness": "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏",
                "readability": "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏",
                "efficiency": "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏",
                "best_practices": "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
            }

        lines = text.split('\n')

        for line in lines:
            line = line.strip()

            # –ü–∞—Ä—Å–∏–º –æ—Ü–µ–Ω–∫—É
            if line.startswith('–û–¶–ï–ù–ö–ê:') or line.startswith('SCORE:'):
                try:
                    # –ò—â–µ–º —á–∏—Å–ª–æ –≤ —Å—Ç—Ä–æ–∫–µ
                    import re
                    numbers = re.findall(r'\d+', line)
                    if numbers:
                        score = int(numbers[0])
                        evaluation["score"] = max(1, min(10, score))
                except:
                    pass

            # –ü–∞—Ä—Å–∏–º —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
            elif line.startswith('–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:') or line.startswith('STRENGTHS:'):
                content = line.split(':', 1)[1].strip()
                strengths = [s.strip() for s in content.split(',') if s.strip()]
                evaluation["strengths"] = strengths[:3]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            elif line.startswith('–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:') or line.startswith('IMPROVEMENTS:') or line.startswith(
                    'RECOMMENDATIONS:'):
                content = line.split(':', 1)[1].strip()
                improvements = [s.strip() for s in content.split(',') if s.strip()]
                evaluation["improvements"] = improvements[:3]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–¥–±–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–∫–∏
        if evaluation["score"] >= 8:
            evaluation["feedback"] = "–û—Ç–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç! –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≥–ª—É–±–æ–∫–∏–µ –∑–Ω–∞–Ω–∏—è –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç."
        elif evaluation["score"] >= 6:
            evaluation["feedback"] = "–•–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç, –Ω–æ –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è."
        else:
            evaluation["feedback"] = "–û—Ç–≤–µ—Ç —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è —Ç–µ–º—ã –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤."

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω/—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
        if not evaluation["strengths"]:
            evaluation["strengths"] = ["–ë–∞–∑–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–º—ã", "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"]

        if not evaluation["improvements"]:
            evaluation["improvements"] = ["–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π", "–ü—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã"]

        return evaluation

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏: {e}")
        return get_fallback_evaluation(contains_code, 5)

def get_fallback_evaluation(contains_code=False, score=5):
    """Fallback –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    if contains_code:
        return {
            "score": score,
            "feedback": "–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.",
            "strengths": ["–†–µ—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ"],
            "improvements": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"],
            "code_analysis": {
                "correctness": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ",
                "readability": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ",
                "efficiency": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ", 
                "best_practices": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ"
            }
        }
    else:
        return {
            "score": score,
            "feedback": "–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.",
            "strengths": ["–û—Ç–≤–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω"],
            "improvements": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
        }

# –ú–∞—Ä—à—Ä—É—Ç—ã Flask
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/setup')
def setup_interview():
    return render_template('setup.html', 
                         positions=AVAILABLE_POSITIONS,
                         levels=AVAILABLE_LEVELS,
                         interview_types=AVAILABLE_INTERVIEW_TYPES,
                         company_types=AVAILABLE_COMPANY_TYPES)

@app.route('/chat')
def chat():
    session_id = request.args.get('session_id')
    if not session_id or session_id not in interview_sessions:
        return redirect(url_for('setup_interview'))
    
    session = interview_sessions[session_id]
    return render_template('chat.html', session=session.to_dict())

@app.route('/api/start_interview', methods=['POST'])
def start_interview():
    try:
        data = request.json
        position = data.get('position', 'Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫')
        level = data.get('level', 'Middle')
        interview_type = data.get('interview_type', '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ')
        company_type = data.get('company_type', 'IT –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è')
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID —Å–µ—Å—Å–∏–∏
        session_id = f"session_{int(time.time())}_{len(interview_sessions)}"
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
        session = InterviewSession(session_id, position, level, interview_type, company_type)
        interview_sessions[session_id] = session
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ LLM
        print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è {position} {level}")
        first_question = generate_interview_question(session)
        session.current_question = first_question
        session.questions_asked.append(first_question)
        session.question_count += 1
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'question': first_question,
            'question_number': session.question_count,
            'total_questions': Config.MAX_QUESTIONS
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/submit_answer', methods=['POST'])
def submit_answer():
    try:
        data = request.json
        session_id = data.get('session_id')
        answer = data.get('answer', '')
        contains_code = data.get('contains_code', False)
        language = data.get('language', 'javascript')
        
        if session_id not in interview_sessions:
            return jsonify({'success': False, 'error': 'Session not found'}), 404
        
        session = interview_sessions[session_id]
        
        if not session.is_active:
            return jsonify({'success': False, 'error': 'Interview completed'}), 400
        
        print(f"üìù –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {session.current_question[:100]}...")
        print(f"üìã –¢–∏–ø –æ—Ç–≤–µ—Ç–∞: {'–∫–æ–¥' if contains_code else '—Ç–µ–∫—Å—Ç'}")
        
        # –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        evaluation = evaluate_answer(
            session.current_question, 
            answer, 
            session.position, 
            session.level,
            contains_code,
            language
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        session.user_answers.append({
            'question': session.current_question,
            'answer': answer,
            'evaluation': evaluation,
            'contains_code': contains_code,
            'language': language if contains_code else None,
            'timestamp': datetime.now().isoformat()
        })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if session.question_count >= Config.MAX_QUESTIONS:
            session.is_active = False
            summary = generate_interview_summary(session)
            return jsonify({
                'success': True,
                'interview_complete': True,
                'evaluation': evaluation,
                'summary': summary
            })
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ LLM
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞...")
        next_question = generate_interview_question(session, session.user_answers)
        session.current_question = next_question
        session.questions_asked.append(next_question)
        session.question_count += 1
        
        return jsonify({
            'success': True,
            'interview_complete': False,
            'question': next_question,
            'question_number': session.question_count,
            'total_questions': Config.MAX_QUESTIONS,
            'evaluation': evaluation
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/test_llm', methods=['POST'])
def test_llm():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM"""
    try:
        test_data = request.json or {}
        message = test_data.get('message', '–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ - —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å?')
        
        messages = [{"role": "user", "content": message}]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º: {message}")
        response = chat_with_model(messages)
        answer = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'request': message,
            'response': answer,
            'model': Config.LLM_MODEL,
            'base_url': Config.LLM_BASE_URL
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'model': Config.LLM_MODEL,
            'base_url': Config.LLM_BASE_URL
        }), 500

@app.route('/api/test_stream', methods=['POST'])
def test_stream():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
    try:
        test_data = request.json or {}
        message = test_data.get('message', '–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –∫—Ä–∞—Ç–∫–æ')
        
        def generate():
            try:
                stream = client.chat.completions.create(
                    model=Config.LLM_MODEL,
                    messages=[{"role": "user", "content": message}],
                    temperature=Config.TEMPERATURE,
                    max_tokens=Config.MAX_TOKENS,
                    stream=True
                )
                
                for chunk in stream:
                    if chunk.choices[0].delta.content is not None:
                        yield f"data: {chunk.choices[0].delta.content}\n\n"
                
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                yield f"data: ‚ùå –û—à–∏–±–∫–∞: {str(e)}\n\n"
        
        return app.response_class(generate(), mimetype='text/plain')
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/test')
def test_llm_page():
    return render_template('test_llm.html')

def generate_interview_summary(session):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ LLM"""
    try:
        answers_text = "\n".join([
            f"–í–æ–ø—Ä–æ—Å {i+1}: {qa['question']}\n–û—Ç–≤–µ—Ç: {qa['answer'][:150]}...\n–û—Ü–µ–Ω–∫–∞: {qa['evaluation']['score']}/10"
            for i, qa in enumerate(session.user_answers)
        ])
        
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∏—Ç–æ–≥–æ–≤—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.

        –î–û–õ–ñ–ù–û–°–¢–¨: {session.position}
        –£–†–û–í–ï–ù–¨: {session.level}
        –¢–ò–ü –ö–û–ú–ü–ê–ù–ò–ò: {session.company_type}
        –í–°–ï–ì–û –í–û–ü–†–û–°–û–í: {len(session.user_answers)}

        –û–¢–í–ï–¢–´ –ö–ê–ù–î–ò–î–ê–¢–ê:
        {answers_text}

        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—â—É—é –∫–∞—Ä—Ç–∏–Ω—É –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
        {{
            "final_score": "—Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª/10 —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º",
            "summary": "–æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
            "strengths": ["–æ—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã (3-4 –ø—É–Ω–∫—Ç–∞)", ...],
            "improvements": ["–∫–ª—é—á–µ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è (3-4 –ø—É–Ω–∫—Ç–∞)", ...], 
            "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é (2-3 –ø—É–Ω–∫—Ç–∞)", ...],
            "verdict": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ –Ω–∞–π–º—É (–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫ –Ω–∞–π–º—É/–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞/–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å)"
        }}
        """

        messages = [
            {
                "role": "system",
                "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–∫—Ä—É—Ç–µ—Ä. –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—à—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å. –¢—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ—à—å —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = chat_with_model(messages)
        summary_text = response.choices[0].message.content.strip()
        summary_text = clean_llm_response(summary_text)
        llm_summary = json.loads(summary_text)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        final_score = calculate_final_score(session)
        summary = {
            'position': session.position,
            'level': session.level,
            'interview_type': session.interview_type,
            'company_type': session.company_type,
            'total_questions': session.question_count,
            'final_score': final_score,
            'duration_minutes': round((datetime.now() - session.start_time).total_seconds() / 60, 1),
            'strengths': llm_summary.get('strengths', []),
            'improvements': llm_summary.get('improvements', []),
            'recommendations': llm_summary.get('recommendations', []),
            'verdict': llm_summary.get('verdict', '–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞'),
            'summary_text': llm_summary.get('summary', f'–ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–±—Ä–∞–ª {final_score}/10 –±–∞–ª–ª–æ–≤.')
        }
        
        return summary
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary —Å LLM: {e}")
        return generate_basic_summary(session)

def generate_basic_summary(session):
    """–ë–∞–∑–æ–≤—ã–π summary –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    total_score = calculate_final_score(session)
    
    if total_score >= 8:
        verdict = "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫ –Ω–∞–π–º—É"
        recommendations = ["–û—Ç–ª–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏", "–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏", "–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ"]
    elif total_score >= 6:
        verdict = "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞" 
        recommendations = ["–•–æ—Ä–æ—à–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞", "–¢—Ä–µ–±—É–µ—Ç—Å—è –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ", "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–æ—Å—Ç–∞"]
    else:
        verdict = "–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å"
        recommendations = ["–¢—Ä–µ–±—É–µ—Ç—Å—è —Å–µ—Ä—å–µ–∑–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —á–µ—Ä–µ–∑ 6-12 –º–µ—Å—è—Ü–µ–≤", "–£–ª—É—á—à–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏"]
    
    return {
        'position': session.position,
        'level': session.level,
        'total_questions': session.question_count,
        'final_score': total_score,
        'duration_minutes': round((datetime.now() - session.start_time).total_seconds() / 60, 1),
        'strengths': ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è", "–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã", "–ú–æ—Ç–∏–≤–∞—Ü–∏—è"],
        'improvements': ["–£–≥–ª—É–±–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç", "–£–ª—É—á—à–∏—Ç—å –Ω–∞–≤—ã–∫–∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á", "–ò–∑—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"],
        'recommendations': recommendations,
        'verdict': verdict,
        'summary_text': f'–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç {total_score}/10 –±–∞–ª–ª–æ–≤ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏.'
    }

def calculate_final_score(session):
    """–†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –±–∞–ª–ª–∞"""
    if not session.user_answers:
        return 0
    
    total_score = sum(answer['evaluation'].get('score', 0) for answer in session.user_answers)
    return round(total_score / len(session.user_answers), 1)

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ Interview AI —Å OpenAI –∫–ª–∏–µ–Ω—Ç–æ–º")
    print(f"üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   Base URL: {Config.LLM_BASE_URL}")
    print(f"   Model: {Config.LLM_MODEL}")
    print(f"   Token: {'***' + Config.LLM_TOKEN[-4:] if Config.LLM_TOKEN else 'None'}")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
