from flask import Flask, request, jsonify, render_template, redirect, url_for
from flask_cors import CORS
from openai import OpenAI
import os
import json
import time
from datetime import datetime

app = Flask(__name__)
CORS(app)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
class Config:
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ SciBox
    LLM_BASE_URL = "https://llm.t1v.scibox.tech/v1"
    LLM_MODEL = "qwen3-32b-awq"
    LLM_TOKEN = "sk-1234"  # ‚ö†Ô∏è –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –†–ï–ê–õ–¨–ù–´–ô –¢–û–ö–ï–ù ‚ö†Ô∏è
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    TEMPERATURE = 0.7
    TOP_P = 0.9
    MAX_TOKENS = 1000
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    INTERVIEW_DURATION = 30
    MAX_QUESTIONS = 5

app.config.from_object(Config)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(
    api_key="sk--hwyMZDmxjPMm50_5LXTiA",
    base_url=Config.LLM_BASE_URL
)

# –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö
class InterviewSession:
    def __init__(self, session_id, position, level, interview_type, company_type):
        self.session_id = session_id
        self.position = position
        self.level = level
        self.interview_type = interview_type
        self.company_type = company_type
        self.questions_asked = []
        self.user_answers = []
        self.current_question = None
        self.start_time = datetime.now()
        self.is_active = True
        self.question_count = 0
        
    def to_dict(self):
        return {
            'session_id': self.session_id,
            'position': self.position,
            'level': self.level,
            'interview_type': self.interview_type,
            'company_type': self.company_type,
            'questions_asked': self.questions_asked,
            'user_answers': self.user_answers,
            'current_question': self.current_question,
            'start_time': self.start_time.isoformat(),
            'is_active': self.is_active,
            'question_count': self.question_count
        }

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π
interview_sessions = {}

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∏ —É—Ä–æ–≤–Ω–∏
AVAILABLE_POSITIONS = {
    "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["HTML/CSS", "JavaScript", "React", "Vue", "TypeScript", "Webpack"],
    "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["Python", "Java", "Node.js", "SQL", "Docker", "AWS"],
    "Data Scientist": ["Python", "Machine Learning", "SQL", "Statistics", "Deep Learning"],
    "DevOps –∏–Ω–∂–µ–Ω–µ—Ä": ["Docker", "Kubernetes", "AWS", "CI/CD", "Linux", "Networking"],
    "Mobile —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": ["Android", "iOS", "React Native", "Flutter", "Kotlin", "Swift"]
}

AVAILABLE_LEVELS = ["Junior", "Middle", "Senior", "Team Lead"]
AVAILABLE_INTERVIEW_TYPES = ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ", "–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–µ", "–°–∏—Å—Ç–µ–º–Ω–æ–µ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ", "–°–º–µ—à–∞–Ω–Ω–æ–µ"]
AVAILABLE_COMPANY_TYPES = ["IT –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è", "–ê—É—Ç—Å–æ—Ä—Å–∏–Ω–≥", "–°—Ç–∞—Ä—Ç–∞–ø", "–ö—Ä—É–ø–Ω–∞—è –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–ì–æ—Å—É—á—Ä–µ–∂–¥–µ–Ω–∏–µ"]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å LLM —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç
def chat_with_model(messages, model=Config.LLM_MODEL):
    try:
        print(f"üîß –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç")
        print(f"   Model: {model}")
        print(f"   Messages: {len(messages)}")
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=Config.TEMPERATURE,
            top_p=Config.TOP_P,
            max_tokens=Config.MAX_TOKENS
        )
        
        print("‚úÖ LLM –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        return response
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å LLM: {e}")
        raise e

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ LLM
def generate_interview_question(session, previous_answers=None):
    try:
        prompt = f"""
        –¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä –Ω–∞ –ø–æ–∑–∏—Ü–∏—é {session.position} —É—Ä–æ–≤–Ω—è {session.level}.
        –¢–∏–ø —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è: {session.interview_type}
        –¢–∏–ø –∫–æ–º–ø–∞–Ω–∏–∏: {session.company_type}
        
        –£–∂–µ –∑–∞–¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: {session.questions_asked[-3:] if session.questions_asked else '–ù–µ—Ç'}
        
        –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –û–î–ò–ù —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è.
        –í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å:
        - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º
        - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —É—Ä–æ–≤–Ω—é –ø–æ–∑–∏—Ü–∏–∏ {session.level}
        - –ù–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã
        - –ü–æ–º–æ—á—å –æ—Ü–µ–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
        """
        
        messages = [
            {
                "role": "system", 
                "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å—ã –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        response = chat_with_model(messages)
        question = response.choices[0].message.content.strip()
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Ç–∞-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        question = clean_llm_response(question)
            
        # –ï—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
        if not question or len(question) < 10:
            print("LLM –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—é fallback")
            return get_fallback_question(session)
            
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –≤–æ–ø—Ä–æ—Å: {question}")
        return question
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞ —Å LLM: {e}")
        return get_fallback_question(session)

def clean_llm_response(text):
    """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM –æ—Ç –ª–∏—à–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
    if not text:
        return text
        
    # –£–¥–∞–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –∫–æ–¥–∞
    text = text.replace('```json', '').replace('```', '').strip()
    
    # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
    prefixes = ["–í–æ–ø—Ä–æ—Å:", "–û—Ç–≤–µ—Ç:", "–û—Ü–µ–Ω–∫–∞:", "JSON:"]
    for prefix in prefixes:
        if text.startswith(prefix):
            text = text[len(prefix):].strip()
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã
    if "\n" in text:
        text = text.split("\n")[0].strip()
        
    return text

def get_fallback_question(session):
    """Fallback –≤–æ–ø—Ä–æ—Å—ã –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    questions_pool = {
        "Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": {
            "Junior": [
                "–û–±—ä—è—Å–Ω–∏—Ç–µ, —á—Ç–æ —Ç–∞–∫–æ–µ DOM –∏ –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç?",
                "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É let, const –∏ var?",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ event delegation –∏ –∑–∞—á–µ–º –æ–Ω–æ –Ω—É–∂–Ω–æ?",
            ],
            "Middle": [
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–≤–æ–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ JavaScript",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π?",
                "–û–±—ä—è—Å–Ω–∏—Ç–µ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É React –∏ Vue",
            ],
            "Senior": [
                "–û–ø–∏—à–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∫—Ä—É–ø–Ω–æ–≥–æ frontend –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞?",
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π",
            ]
        },
        "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫": {
            "Junior": [
                "–ß—Ç–æ —Ç–∞–∫–æ–µ REST API?",
                "–û–±—ä—è—Å–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –û–û–ü",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ SQL –∏–Ω—ä–µ–∫—Ü–∏–∏ –∏ –∫–∞–∫ –∏—Ö –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å?",
            ],
            "Middle": [
                "–û–ø–∏—à–∏—Ç–µ –≤–∞—à –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å API?",
                "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã —Å –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏",
            ],
            "Senior": [
                "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤",
                "–ö–∞–∫ –≤—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç–µ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã?",
                "–û–ø–∏—à–∏—Ç–µ –≤–∞—à –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å message brokers",
            ]
        }
    }
    
    position_questions = questions_pool.get(session.position, questions_pool["Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"])
    level_questions = position_questions.get(session.level, position_questions["Middle"])
    available_questions = [q for q in level_questions if q not in session.questions_asked]
    
    if available_questions:
        return available_questions[0]
    else:
        return f"–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–∞–º–æ–º —Å–ª–æ–∂–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {session.position}, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å?"

# –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM
def evaluate_answer(question, answer, position, level, contains_code=False, language=None):
    try:
        if contains_code:
            prompt = f"""
            [–°–¢–†–û–ì–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø: –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –ë–ï–ó –õ–Æ–ë–û–ì–û –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê]

            –¢—ã - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä –Ω–∞ –ø–æ–∑–∏—Ü–∏—é {position} —É—Ä–æ–≤–Ω—è {level}.
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ –¥–∞–π –æ–±—ä–µ–∫—Ç–∏–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É.

            –í–û–ü–†–û–°: {question}
            
            –ö–û–î –ö–ê–ù–î–ò–î–ê–¢–ê (—è–∑—ã–∫: {language}):
            ```{language}
            {answer}
            ```

            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∏ –ø–æ—Å—Ç–∞–≤—å –æ—Ü–µ–Ω–∫—É –æ—Ç 1 –¥–æ 10:
            - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è
            - –ö–∞—á–µ—Å—Ç–≤–æ –∏ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞
            - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞  
            - –û–±—Ä–∞–±–æ—Ç–∫–∞ edge cases
            - –°–ª–µ–¥–æ–≤–∞–Ω–∏–µ best practices

            –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON:
            {{
                "score": —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10,
                "feedback": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å",
                "strengths": ["—Å–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 1", "—Å–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 2"],
                "improvements": ["—É–ª—É—á—à–µ–Ω–∏–µ 1", "—É–ª—É—á—à–µ–Ω–∏–µ 2"],
                "code_analysis": {{
                    "correctness": "–æ—Ü–µ–Ω–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏",
                    "readability": "–æ—Ü–µ–Ω–∫–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏",
                    "efficiency": "–æ—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
                    "best_practices": "—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ best practices"
                }}
            }}
            """
        else:
            prompt = f"""
            [–°–¢–†–û–ì–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø: –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –ë–ï–ó –õ–Æ–ë–û–ì–û –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê]

            –¢—ã - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä –Ω–∞ –ø–æ–∑–∏—Ü–∏—é {position} —É—Ä–æ–≤–Ω—è {level}.
            –û—Ü–µ–Ω–∏ –æ—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

            –í–û–ü–†–û–°: {question}
            
            –û–¢–í–ï–¢ –ö–ê–ù–î–ò–î–ê–¢–ê: {answer}

            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∏ –ø–æ—Å—Ç–∞–≤—å –æ—Ü–µ–Ω–∫—É –æ—Ç 1 –¥–æ 10:
            - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≥–ª—É–±–∏–Ω–∞ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å
            - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –∑–Ω–∞–Ω–∏–π
            - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
            - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Ä–æ–≤–Ω—é –ø–æ–∑–∏—Ü–∏–∏
            - –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

            –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON:
            {{
                "score": —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10,
                "feedback": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å",
                "strengths": ["—Å–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 1", "—Å–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 2"],
                "improvements": ["—É–ª—É—á—à–µ–Ω–∏–µ 1", "—É–ª—É—á—à–µ–Ω–∏–µ 2"]
            }}
            """

        messages = [
            {
                "role": "system",
                "content": "–¢—ã —Å—Ç—Ä–æ–≥–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON. –ù–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        print(f"üìä –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Ü–µ–Ω–∫—É –æ—Ç–≤–µ—Ç–∞")
        response = chat_with_model(messages)
        evaluation_text = response.choices[0].message.content.strip()
        
        print(f"üì® –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM: {evaluation_text[:200]}...")
        
        # –û—á–∏—Å—Ç–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON
        evaluation_text = clean_llm_response(evaluation_text)
        evaluation = json.loads(evaluation_text)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
        if 'score' not in evaluation:
            evaluation['score'] = 5
        else:
            evaluation['score'] = max(1, min(10, int(evaluation['score'])))
            
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –µ—Å–ª–∏ —ç—Ç–æ –∫–æ–¥
        if contains_code and 'code_analysis' not in evaluation:
            evaluation['code_analysis'] = {
                "correctness": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω",
                "readability": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω", 
                "efficiency": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω",
                "best_practices": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω"
            }
            
        print(f"‚úÖ –û—Ü–µ–Ω–∫–∞ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞: {evaluation['score']}/10")
        return evaluation
        
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return get_fallback_evaluation(contains_code, 5)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return get_fallback_evaluation(contains_code, 5)

def get_fallback_evaluation(contains_code=False, score=5):
    """Fallback –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    if contains_code:
        return {
            "score": score,
            "feedback": "–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.",
            "strengths": ["–†–µ—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ"],
            "improvements": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"],
            "code_analysis": {
                "correctness": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ",
                "readability": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ",
                "efficiency": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ", 
                "best_practices": "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ"
            }
        }
    else:
        return {
            "score": score,
            "feedback": "–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.",
            "strengths": ["–û—Ç–≤–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω"],
            "improvements": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
        }

# –ú–∞—Ä—à—Ä—É—Ç—ã Flask
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/setup')
def setup_interview():
    return render_template('setup.html', 
                         positions=AVAILABLE_POSITIONS,
                         levels=AVAILABLE_LEVELS,
                         interview_types=AVAILABLE_INTERVIEW_TYPES,
                         company_types=AVAILABLE_COMPANY_TYPES)

@app.route('/chat')
def chat():
    session_id = request.args.get('session_id')
    if not session_id or session_id not in interview_sessions:
        return redirect(url_for('setup_interview'))
    
    session = interview_sessions[session_id]
    return render_template('chat.html', session=session.to_dict())

@app.route('/api/start_interview', methods=['POST'])
def start_interview():
    try:
        data = request.json
        position = data.get('position', 'Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫')
        level = data.get('level', 'Middle')
        interview_type = data.get('interview_type', '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ')
        company_type = data.get('company_type', 'IT –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è')
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID —Å–µ—Å—Å–∏–∏
        session_id = f"session_{int(time.time())}_{len(interview_sessions)}"
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
        session = InterviewSession(session_id, position, level, interview_type, company_type)
        interview_sessions[session_id] = session
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ LLM
        print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è {position} {level}")
        first_question = generate_interview_question(session)
        session.current_question = first_question
        session.questions_asked.append(first_question)
        session.question_count += 1
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'question': first_question,
            'question_number': session.question_count,
            'total_questions': Config.MAX_QUESTIONS
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/submit_answer', methods=['POST'])
def submit_answer():
    try:
        data = request.json
        session_id = data.get('session_id')
        answer = data.get('answer', '')
        contains_code = data.get('contains_code', False)
        language = data.get('language', 'javascript')
        
        if session_id not in interview_sessions:
            return jsonify({'success': False, 'error': 'Session not found'}), 404
        
        session = interview_sessions[session_id]
        
        if not session.is_active:
            return jsonify({'success': False, 'error': 'Interview completed'}), 400
        
        print(f"üìù –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {session.current_question[:100]}...")
        print(f"üìã –¢–∏–ø –æ—Ç–≤–µ—Ç–∞: {'–∫–æ–¥' if contains_code else '—Ç–µ–∫—Å—Ç'}")
        
        # –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        evaluation = evaluate_answer(
            session.current_question, 
            answer, 
            session.position, 
            session.level,
            contains_code,
            language
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        session.user_answers.append({
            'question': session.current_question,
            'answer': answer,
            'evaluation': evaluation,
            'contains_code': contains_code,
            'language': language if contains_code else None,
            'timestamp': datetime.now().isoformat()
        })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
        if session.question_count >= Config.MAX_QUESTIONS:
            session.is_active = False
            summary = generate_interview_summary(session)
            return jsonify({
                'success': True,
                'interview_complete': True,
                'evaluation': evaluation,
                'summary': summary
            })
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ LLM
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞...")
        next_question = generate_interview_question(session, session.user_answers)
        session.current_question = next_question
        session.questions_asked.append(next_question)
        session.question_count += 1
        
        return jsonify({
            'success': True,
            'interview_complete': False,
            'question': next_question,
            'question_number': session.question_count,
            'total_questions': Config.MAX_QUESTIONS,
            'evaluation': evaluation
        })
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/test_llm', methods=['POST'])
def test_llm():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM"""
    try:
        test_data = request.json or {}
        message = test_data.get('message', '–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ - —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å?')
        
        messages = [{"role": "user", "content": message}]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º: {message}")
        response = chat_with_model(messages)
        answer = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'request': message,
            'response': answer,
            'model': Config.LLM_MODEL,
            'base_url': Config.LLM_BASE_URL
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'model': Config.LLM_MODEL,
            'base_url': Config.LLM_BASE_URL
        }), 500

@app.route('/api/test_stream', methods=['POST'])
def test_stream():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
    try:
        test_data = request.json or {}
        message = test_data.get('message', '–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –∫—Ä–∞—Ç–∫–æ')
        
        def generate():
            try:
                stream = client.chat.completions.create(
                    model=Config.LLM_MODEL,
                    messages=[{"role": "user", "content": message}],
                    temperature=Config.TEMPERATURE,
                    max_tokens=Config.MAX_TOKENS,
                    stream=True
                )
                
                for chunk in stream:
                    if chunk.choices[0].delta.content is not None:
                        yield f"data: {chunk.choices[0].delta.content}\n\n"
                
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                yield f"data: ‚ùå –û—à–∏–±–∫–∞: {str(e)}\n\n"
        
        return app.response_class(generate(), mimetype='text/plain')
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/test')
def test_llm_page():
    return render_template('test_llm.html')

def generate_interview_summary(session):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ LLM"""
    try:
        answers_text = "\n".join([
            f"–í–æ–ø—Ä–æ—Å {i+1}: {qa['question']}\n–û—Ç–≤–µ—Ç: {qa['answer'][:150]}...\n–û—Ü–µ–Ω–∫–∞: {qa['evaluation']['score']}/10"
            for i, qa in enumerate(session.user_answers)
        ])
        
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∏—Ç–æ–≥–æ–≤—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.

        –î–û–õ–ñ–ù–û–°–¢–¨: {session.position}
        –£–†–û–í–ï–ù–¨: {session.level}
        –¢–ò–ü –ö–û–ú–ü–ê–ù–ò–ò: {session.company_type}
        –í–°–ï–ì–û –í–û–ü–†–û–°–û–í: {len(session.user_answers)}

        –û–¢–í–ï–¢–´ –ö–ê–ù–î–ò–î–ê–¢–ê:
        {answers_text}

        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—â—É—é –∫–∞—Ä—Ç–∏–Ω—É –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
        {{
            "final_score": "—Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª/10 —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º",
            "summary": "–æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
            "strengths": ["–æ—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã (3-4 –ø—É–Ω–∫—Ç–∞)", ...],
            "improvements": ["–∫–ª—é—á–µ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è (3-4 –ø—É–Ω–∫—Ç–∞)", ...], 
            "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é (2-3 –ø—É–Ω–∫—Ç–∞)", ...],
            "verdict": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ –Ω–∞–π–º—É (–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫ –Ω–∞–π–º—É/–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞/–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å)"
        }}
        """

        messages = [
            {
                "role": "system",
                "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–∫—Ä—É—Ç–µ—Ä. –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—à—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å. –¢—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ—à—å —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = chat_with_model(messages)
        summary_text = response.choices[0].message.content.strip()
        summary_text = clean_llm_response(summary_text)
        llm_summary = json.loads(summary_text)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        final_score = calculate_final_score(session)
        summary = {
            'position': session.position,
            'level': session.level,
            'interview_type': session.interview_type,
            'company_type': session.company_type,
            'total_questions': session.question_count,
            'final_score': final_score,
            'duration_minutes': round((datetime.now() - session.start_time).total_seconds() / 60, 1),
            'strengths': llm_summary.get('strengths', []),
            'improvements': llm_summary.get('improvements', []),
            'recommendations': llm_summary.get('recommendations', []),
            'verdict': llm_summary.get('verdict', '–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞'),
            'summary_text': llm_summary.get('summary', f'–ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–±—Ä–∞–ª {final_score}/10 –±–∞–ª–ª–æ–≤.')
        }
        
        return summary
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary —Å LLM: {e}")
        return generate_basic_summary(session)

def generate_basic_summary(session):
    """–ë–∞–∑–æ–≤—ã–π summary –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
    total_score = calculate_final_score(session)
    
    if total_score >= 8:
        verdict = "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫ –Ω–∞–π–º—É"
        recommendations = ["–û—Ç–ª–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏", "–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏", "–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ"]
    elif total_score >= 6:
        verdict = "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞" 
        recommendations = ["–•–æ—Ä–æ—à–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞", "–¢—Ä–µ–±—É–µ—Ç—Å—è –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ", "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–æ—Å—Ç–∞"]
    else:
        verdict = "–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å"
        recommendations = ["–¢—Ä–µ–±—É–µ—Ç—Å—è —Å–µ—Ä—å–µ–∑–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —á–µ—Ä–µ–∑ 6-12 –º–µ—Å—è—Ü–µ–≤", "–£–ª—É—á—à–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏"]
    
    return {
        'position': session.position,
        'level': session.level,
        'total_questions': session.question_count,
        'final_score': total_score,
        'duration_minutes': round((datetime.now() - session.start_time).total_seconds() / 60, 1),
        'strengths': ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è", "–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã", "–ú–æ—Ç–∏–≤–∞—Ü–∏—è"],
        'improvements': ["–£–≥–ª—É–±–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç", "–£–ª—É—á—à–∏—Ç—å –Ω–∞–≤—ã–∫–∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á", "–ò–∑—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"],
        'recommendations': recommendations,
        'verdict': verdict,
        'summary_text': f'–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç {total_score}/10 –±–∞–ª–ª–æ–≤ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏.'
    }

def calculate_final_score(session):
    """–†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –±–∞–ª–ª–∞"""
    if not session.user_answers:
        return 0
    
    total_score = sum(answer['evaluation'].get('score', 0) for answer in session.user_answers)
    return round(total_score / len(session.user_answers), 1)

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ Interview AI —Å OpenAI –∫–ª–∏–µ–Ω—Ç–æ–º")
    print(f"üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   Base URL: {Config.LLM_BASE_URL}")
    print(f"   Model: {Config.LLM_MODEL}")
    print(f"   Token: {'***' + Config.LLM_TOKEN[-4:] if Config.LLM_TOKEN else 'None'}")
    
    app.run(debug=True, host='0.0.0.0', port=5000)